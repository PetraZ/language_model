{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c931fd",
   "metadata": {},
   "source": [
    "Ngram is similar to bi-gram. instead using prev char to predict next char, it uses n chars to predict next char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9682f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5230fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the words\n",
    "with open(\"names.txt\") as f:\n",
    "    words = f.read().split()\n",
    "    \n",
    "## build the map \n",
    "char_set = sorted(set(''.join(words)))\n",
    "ctoi = {c:i+1 for i, c in enumerate(char_set)}\n",
    "ctoi['.'] = 0\n",
    "itoc = {i:c for c, i in ctoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a9fa25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3])\n",
      "torch.Size([228146])\n"
     ]
    }
   ],
   "source": [
    "## build the nn dataset \n",
    "xs, ys = [], []\n",
    "n_gram = 3\n",
    "\n",
    "for w in words:\n",
    "    chars = [\".\"] * n_gram + list(w) + [\".\"]\n",
    "    for i in range(n_gram, len(chars)):\n",
    "        xs.append(list(map(lambda x: ctoi[x], chars[i-n_gram:i])))\n",
    "        ys.append(ctoi[chars[i]])\n",
    "\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "print(xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9ab5d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total 9367 params\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 20\n",
    "hidden_layer_size = 100\n",
    "\n",
    "E = torch.randn((27, embedding_size))\n",
    "W1 = torch.randn((n_gram * embedding_size, hidden_layer_size))\n",
    "b1 = torch.randn((hidden_layer_size,))\n",
    "W2 = torch.randn((hidden_layer_size, 27))\n",
    "b2 = torch.randn(27)\n",
    "\n",
    "params = [E, W1, b1, W2, b2]\n",
    "num_params = 0\n",
    "for p in params:\n",
    "    p.requires_grad = True\n",
    "    num_params += p.nelement()\n",
    "print(f\"in total {num_params} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6c55c902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 2.032038450241089\n"
     ]
    }
   ],
   "source": [
    "batch_size= 32\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    sample_idx = torch.randint(len(xs), (batch_size,))\n",
    "    bxs = xs[sample_idx]\n",
    "    bys = ys[sample_idx]\n",
    "     \n",
    "    h = (E[bxs].view(batch_size, -1) @ W1) + b1\n",
    "    logits = h @ W2 + b2\n",
    "    \n",
    "    loss = F.cross_entropy(logits, bys)\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    ## update the weights\n",
    "    for p in params:\n",
    "        p.data += -0.01 * p.grad\n",
    "        p.grad = None\n",
    "        \n",
    "print(f\"loss is {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7cffe33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2830, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = (E[xs].view(xs.shape[0], -1) @ W1) + b1\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, ys)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c239ddf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9bdb2c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candea\n",
      "cavi\n",
      "ngeda\n",
      "ore\n",
      "had\n",
      "jaylyan\n",
      "eya\n",
      "kandy\n",
      "rasta\n",
      "blaxi\n",
      "zliy\n",
      "rasyavarigkond\n",
      "karlon\n",
      "kruwston\n",
      "rhombryx\n",
      "cyd\n",
      "hlen\n",
      "aniy\n",
      "gouty\n",
      "hlae\n",
      "jeios\n",
      "rule\n",
      "ley\n",
      "kanizlie\n",
      "phiskcors\n",
      "badirke\n",
      "sakinn\n",
      "bri\n",
      "hadel\n",
      "kunzaifan\n",
      "araak\n",
      "philla\n",
      "madayorhsarson\n",
      "jannn\n",
      "daxsur\n",
      "nar\n",
      "jula\n",
      "kemeadyla\n",
      "had\n",
      "yah\n",
      "manterdia\n",
      "kalloynnex\n",
      "iom\n",
      "kerzelisen\n",
      "keve\n",
      "rom\n",
      "uth\n",
      "rovialya\n",
      "lya\n",
      "ayh\n",
      "reshailei\n",
      "kaly\n",
      "jana\n",
      "yahayd\n",
      "tor\n",
      "rmiytraharulet\n",
      "ale\n",
      "hal\n",
      "dareliam\n",
      "zuelaknyasahmajolyna\n",
      "aaydolwinthamuki\n",
      "erdona\n",
      "elyin\n",
      "odri\n",
      "ayly\n",
      "aveylan\n",
      "ken\n",
      "aellyle\n",
      "nide\n",
      "shriy\n",
      "jalaya\n",
      "antayhro\n",
      "elbylin\n",
      "aiahalyen\n",
      "brislon\n",
      "elben\n",
      "jamasca\n",
      "kamira\n",
      "khoniyanno\n",
      "evish\n",
      "bynta\n",
      "kys\n",
      "brige\n",
      "devictiebra\n",
      "dev\n",
      "asslen\n",
      "chandila\n",
      "parlenth\n",
      "ahlel\n",
      "cha\n",
      "eigh\n",
      "kaetanjeylan\n",
      "oun\n",
      "abibostan\n",
      "jer\n",
      "hamith\n",
      "rack\n",
      "ellen\n",
      "shi\n",
      "thera\n"
     ]
    }
   ],
   "source": [
    "## pred\n",
    "g = torch.Generator().manual_seed(1234)\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    x = torch.zeros((1, 3), dtype=torch.int64)\n",
    "    word = \"\"\n",
    "    while True:\n",
    "        h = (E[x].view(x.shape[0], -1) @ W1) + b1\n",
    "        logits = h @ W2 + b2\n",
    "        probs = logits.squeeze().exp() / logits.squeeze().exp().sum()\n",
    "\n",
    "        idx = torch.multinomial(probs, 1, replacement=True, generator = g).item()\n",
    "\n",
    "        if idx == 0:\n",
    "            break\n",
    "\n",
    "        word += itoc[idx]\n",
    "        x[0,0], x[0,1], x[0,2] = x[0,1], x[0,2], idx\n",
    "        \n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe588ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7279b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d0378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
